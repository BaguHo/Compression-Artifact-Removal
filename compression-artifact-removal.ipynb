{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b91a3-2b8b-4a2c-927f-3d7049165c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "\u001b[1;31m    from ipykernel import kernelapp as app\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 21, in <module>\n",
      "\u001b[1;31m    from IPython.core.application import (  # type:ignore[attr-defined]\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/__init__.py\", line 55, in <module>\n",
      "\u001b[1;31m    from .terminal.embed import embed\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/terminal/embed.py\", line 15, in <module>\n",
      "\u001b[1;31m    from IPython.core.interactiveshell import DummyMod, InteractiveShell\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 110, in <module>\n",
      "\u001b[1;31m    from IPython.core.history import HistoryManager\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/history.py\", line 10, in <module>\n",
      "\u001b[1;31m    import sqlite3\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/sqlite3/__init__.py\", line 57, in <module>\n",
      "\u001b[1;31m    from sqlite3.dbapi2 import *\n",
      "\u001b[1;31m  File \"/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/sqlite3/dbapi2.py\", line 27, in <module>\n",
      "\u001b[1;31m    from _sqlite3 import *\n",
      "\u001b[1;31mImportError: dlopen(/Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/lib-dynload/_sqlite3.cpython-312-darwin.so, 0x0002): Symbol not found: _sqlite3_enable_load_extension\n",
      "\u001b[1;31m  Referenced from: <4C8A356C-740E-3A20-8BFB-F406623A870F> /Users/eomjiho/miniforge3/envs/pytorch/lib/python3.12/lib-dynload/_sqlite3.cpython-312-darwin.so\n",
      "\u001b[1;31m  Expected in:     <EA38CD98-B566-3679-9D29-6543317DF40D> /usr/lib/libsqlite3.dylib. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init\n",
    "import torch.optim as optim \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, confusion_matrix\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04ab5a88-2a04-446e-b3d6-d7a569c72082",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33ada2eb-f0c2-43ca-a52a-785ab700d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root=\"./datasets/\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets/\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "901080fb-cc10-4446-bb6e-b181539b72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cafe2e10-f704-42e6-8916-0f5833dea535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Loss: 0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Loss: 0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 98.76%\n",
      "Results saved to './result.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 학습\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)  \n",
    "            loss = criterion(outputs, labels) \n",
    "\n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "        \n",
    "# 모델 평가\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device) \n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    precision_per_class = precision_score(all_targets, all_predictions, average=None)\n",
    "    precision_avg = precision_score(all_targets, all_predictions, average='macro')\n",
    "    \n",
    "    print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy, precision_avg\n",
    "\n",
    "# 결과 저장\n",
    "def save_result(model_name = \"CNN\", accuracy = None, precision = None):    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Model Name': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision]\n",
    "    })\n",
    "    results_df.to_csv('./result.csv', index=False)\n",
    "    print(\"Results saved to './result.csv'\")\n",
    "\n",
    "# 모델 학습 및 평가 실행\n",
    "train(model, train_loader, criterion, optimizer)\n",
    "accuracy, precision = test(model, test_loader)\n",
    "\n",
    "save_result(\"CNN\", accuracy, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b41e80a6-f186-4007-87b5-4637f01764c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir(path): \n",
    "   try: \n",
    "        os.makedirs(path) \n",
    "   except OSError: \n",
    "       if not os.path.isdir(path): \n",
    "           raise\n",
    "\n",
    "train_output_dir = './datasets/MNIST/jpeg90/train/'\n",
    "test_output_dir = './datasets/MNIST/jpeg90/test/'\n",
    "\n",
    "makedir(train_output_dir)\n",
    "makedir(test_output_dir)\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "mnist_dataset_train = datasets.MNIST(root=\"./datasets/\", train=True, download=True)\n",
    "mnist_dataset_test = datasets.MNIST(root=\"./datasets/\", train=False, download=True)\n",
    "\n",
    "# MNIST 데이터셋의 각 이미지를 JPEG로 변환 및 저장\n",
    "for idx, (image, label) in enumerate(mnist_dataset_train):\n",
    "    # 이미지 파일 이름 생성\n",
    "    file_name = f\"image_{idx}_label_{label}.jpg\"\n",
    "    output_file_path = os.path.join(train_output_dir, file_name)\n",
    "    \n",
    "    # JPEG로 저장 (퀄리티 90)\n",
    "    image.convert('RGB').save(output_file_path, 'JPEG', quality=90)\n",
    "\n",
    "\n",
    "# MNIST 데이터셋의 각 이미지를 JPEG로 변환 및 저장\n",
    "for idx, (image, label) in enumerate(mnist_dataset_test):\n",
    "    # 이미지 파일 이름 생성\n",
    "    file_name = f\"image_{idx}_label_{label}.jpg\"\n",
    "    output_file_path = os.path.join(test_output_dir, file_name)\n",
    "    \n",
    "    # JPEG로 저장 (퀄리티 90)\n",
    "    image.convert('RGB').save(output_file_path, 'JPEG', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cda05a9d-f8b2-4a2e-b8b6-5e881efdbfa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in ./datasets/MNIST/jpeg90/train/0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     14\u001b[0m     train_source_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(jpeg_90_train_dir, \u001b[38;5;28mstr\u001b[39m(i))\n\u001b[1;32m---> 15\u001b[0m     jpeg_90_train \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(train_source_dir, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m     16\u001b[0m     jpeg_90_train_loader \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m DataLoader(jpeg_90_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m     test_source_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(jpeg_90_test_dir, \u001b[38;5;28mstr\u001b[39m(i))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    329\u001b[0m         root,\n\u001b[0;32m    330\u001b[0m         loader,\n\u001b[0;32m    331\u001b[0m         IMG_EXTENSIONS \u001b[38;5;28;01mif\u001b[39;00m is_valid_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    332\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[0;32m    333\u001b[0m         target_transform\u001b[38;5;241m=\u001b[39mtarget_transform,\n\u001b[0;32m    334\u001b[0m         is_valid_file\u001b[38;5;241m=\u001b[39mis_valid_file,\n\u001b[0;32m    335\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    336\u001b[0m     )\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:43\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     41\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m class_to_idx \u001b[38;5;241m=\u001b[39m {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in ./datasets/MNIST/jpeg90/train/0."
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "jpeg_90_train_dir = './datasets/MNIST/jpeg90/train/'\n",
    "jpeg_90_test_dir = './datasets/MNIST/jpeg90/test/'\n",
    "\n",
    "jpeg_90_train_loader = None\n",
    "jpeg_90_test_loader = None\n",
    "\n",
    "for i in range(10):\n",
    "    train_source_dir = os.path.join(jpeg_90_train_dir, str(i))\n",
    "    jpeg_90_train = datasets.ImageFolder(train_source_dir, transform=transform)\n",
    "    jpeg_90_train_loader += DataLoader(jpeg_90_train, batch_size=64, shuffle=True)\n",
    "    \n",
    "    test_source_dir = os.path.join(jpeg_90_test_dir, str(i))\n",
    "    jepg_90_test += datasets.ImageFolder(test_source_dir, transform=transform)\n",
    "    jpeg_90_test_loader += DataLoader(jpeg_90_test, batch_size=64, shuffle=False)\n",
    "    \n",
    "# jpeg_90_train = datasets.ImageFolder(jpeg_90_train_dir, transform=transform)\n",
    "# jpeg_90_test = datasets.ImageFolder(jpeg_90_test_dir, transform=transform)\n",
    "\n",
    "# jpeg_90_train_loader = DataLoader(jpeg_90_train, batch_size=64, shuffle=True)\n",
    "# jpeg_90_test_loader = DataLoader(jpeg_90_test, batch_size=64, shuffle=False)\n",
    "\n",
    "jpeg_90_model = CNN().to(device)\n",
    "\n",
    "train(jpeg_90_model, jpeg_90_train_loader, criterion, optimizer)\n",
    "accuracy, precision = test(jpeg_90_model, jpeg_90_test_loader)\n",
    "\n",
    "save_result(\"JPEG 90 CNN\", accuracy, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af8596-498c-49ae-b0df-d6ed057c1052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
